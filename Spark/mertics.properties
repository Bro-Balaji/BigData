spark.metrics.conf.*.sink.graphite.class org.apache.spark.metrics.sink.GraphiteSink
spark.metrics.conf.*.sink.graphite.host <graphite db host>
spark.metrics.conf.*.sink.graphite.port 2003
spark.metrics.conf.*.sink.graphite.period 10
spark.metrics.conf.*.sink.graphite.unit seconds
spark.metrics.conf.*.sink.graphite.prefix jiooneseg
spark.metrics.conf.*.source.jvm.class org.apache.spark.metrics.source.JvmSource
spark.metrics.staticSources.enabled true
spark.metrics.appStatusSource.enabled true


spark-submit --properties-file metrics.properties --files /etc/hive/conf/hive-site.xml --master yarn --deploy-mode cluster --queue <queue name> --name <job name> --conf 'spark.network.timeout=10000000' --conf 'spark.sql.broadcastTimeout=600000' --conf 'spark.executor.heartbeatInterval=1000000' --conf 'spark.shuffle.service.port=7337' --conf 'spark.sql.shuffle.partitions=1500' --conf 'spark.shuffle.service.enabled=true' --conf 'spark.shuffle.compress=true' --conf 'spark.driver.maxResultSize=5g' --executor-memory 25g --executor-cores 5 --driver-memory 4g --conf 'spark.dynamicAllocation.enabled=true' --conf 'spark.dynamicAllocation.minExecutors=2' --conf 'spark.dynamicAllocation.initialExecutors=2' --conf 'spark.dynamicAllocation.maxExecutors=40' --conf 'spark.yarn.maxAppAttempts=1' --conf 'spark.executor.extraJavaOptions=-XX:+UseG1GC -XX:+UseStringDeduplication' <python script>
